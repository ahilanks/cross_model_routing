{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0795696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples: 14186\n",
      "Number of negative samples: 3811\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"base\": \"Qwen/Qwen2.5-1.5B-Instruct\", # base model\n",
    "    \"device\": torch.device(\"cuda\"),\n",
    "\n",
    "    # model names and prices\n",
    "    \"model_keys\": {\n",
    "        'gpt-5-nano-2025-08-07_response': (0.05, 0.40),\n",
    "        'grok-4-fast-reasoning_response': (0.20, 0.50),\n",
    "        'openai_gpt-oss-120b_response': (0.05, 0.24),\n",
    "        'openai_gpt-oss-20b_response': (0.03, 0.14),\n",
    "        'nvidia_NVIDIA-Nemotron-Nano-9B-v2_response': (0.04, 0.16),\n",
    "        'meta-llama_Llama-3.2-11B-Vision-Instruct_response': (0.049, 0.049),\n",
    "        'moonshotai_Kimi-K2-Instruct-0905_response': (0.50, 2.00),\n",
    "        'gemini-2.5-flash-lite_response': (0.10, 0.40),\n",
    "    },\n",
    "\n",
    "    \"PEAK_LR\": 1e-6,\n",
    "    \"BATCH_SIZE\": 16,\n",
    "    \"EPOCHS\": 8,\n",
    "    \"WEIGHT_DECAY\": 0.04,\n",
    "    \"NUM_WARMUP_STEPS\": 50,\n",
    "    \"SAVE_PATH\": \"models/router_qwen2.5\"\n",
    "}\n",
    "\n",
    "def load_data(file_path, length=None):\n",
    "    records = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if length and len(records) >= length:\n",
    "                break\n",
    "            try:\n",
    "                records.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"Bad line:\", e)\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # merge by model keys\n",
    "    grouped = df.groupby(\"index\")\n",
    "    merged_rows = []\n",
    "    for idx, group in grouped:\n",
    "        merged_row = group.iloc[0].copy()\n",
    "        for m in CONFIG[\"model_keys\"]:\n",
    "            vals = group[m].dropna().tolist()\n",
    "            if vals:\n",
    "                merged_row[m] = vals[-1]\n",
    "        merged_rows.append(merged_row)\n",
    "    df = pd.DataFrame(merged_rows).reset_index(drop=True)\n",
    "\n",
    "    # clean & get is_correct, and total_price\n",
    "    for idx, row in df.iterrows():\n",
    "        for col in CONFIG[\"model_keys\"].keys():\n",
    "            if pd.notna(row.get(col)) and isinstance(row[col], dict):\n",
    "                entry = row[col].copy()\n",
    "\n",
    "                # parse final answer\n",
    "                answer = entry.get('answer', '')\n",
    "                if answer and 'Final Answer:' in answer:\n",
    "                    final_answer_str = answer.split(\"Final Answer:\")[1].strip()\n",
    "                    try:\n",
    "                        final_answer = int(final_answer_str)\n",
    "                    except ValueError:\n",
    "                        final_answer = 0\n",
    "                    entry['final_answer'] = final_answer\n",
    "\n",
    "                    correct_answer = row.get('correct_answer', '')\n",
    "                    entry['is_correct'] = (final_answer == correct_answer)\n",
    "\n",
    "                # compute total price\n",
    "                input_tokens = entry.get('input_tokens', 0)\n",
    "                output_tokens = entry.get('output_tokens', 0)\n",
    "                input_rate, output_rate = CONFIG[\"model_keys\"][col]\n",
    "                entry['total_price'] = (input_tokens * (input_rate / 1000000) + output_tokens * (output_rate / 1000000)) * 1000 # kind of normalizing\n",
    "\n",
    "                # default missing numeric fields to 0\n",
    "                entry['total_latency'] = entry.get('total_latency', 0) or 0\n",
    "                entry['is_correct'] = entry.get('is_correct', False)\n",
    "\n",
    "                df.at[idx, col] = entry\n",
    "\n",
    "    # Drop rows with missing or invalid question\n",
    "    df = df[df['question'].notna() & (df['question'] != '')].reset_index(drop=True)\n",
    "\n",
    "    # Ensure no nulls in key model fields (example: gemini)\n",
    "    key_model = 'gemini-2.5-flash-lite_response'\n",
    "    df = df[\n",
    "        df[key_model].apply(lambda x: isinstance(x, dict) and all(k in x and x[k] is not None for k in ['is_correct', 'total_latency', 'total_price']))\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    # Split into train and validation\n",
    "    df_train = df.sample(frac=0.9, random_state=42)\n",
    "    df_val = df.drop(df_train.index).reset_index(drop=True)\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "    return df_train, df_val\n",
    "\n",
    "df_train, df_val = load_data(\"data/all_providers_results_parallelized.jsonl\")\n",
    "df_train, df_val = df_train[['question', 'gemini-2.5-flash-lite_response']], df_val[['question', 'gemini-2.5-flash-lite_response']]\n",
    "num_pos = sum(df_train['gemini-2.5-flash-lite_response'].apply(lambda d: d['is_correct']))\n",
    "num_neg = len(df_train) - num_pos\n",
    "print(f\"Number of positive samples: {num_pos}\")\n",
    "print(f\"Number of negative samples: {num_neg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
