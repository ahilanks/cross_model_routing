_wandb:
    value:
        cli_version: 0.23.0
        e:
            wcbwlxdcd8v0mwr49iqro9glikqfdqim:
                codePath: router_final.py
                codePathLocal: router_final.py
                cpu_count: 128
                cpu_count_logical: 256
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "32212254720"
                        used: "829112320"
                email: ahilanks101@gmail.com
                executable: /usr/local/bin/python
                git:
                    commit: ae5cfce89f16cf28af2a586d42206850810ff458
                    remote: https://github.com/ahilanks/cross_model_routing.git
                gpu: NVIDIA H100 PCIe
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Hopper
                      cudaCores: 14592
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 PCIe
                      uuid: GPU-6204850c-847b-daec-8d96-950a15d9b548
                host: 71611d8bf72d
                memory:
                    total: "2151604916224"
                os: Linux-6.8.0-60-generic-x86_64-with-glibc2.39
                program: /workspace/router_final.py
                python: CPython 3.12.3
                root: /workspace
                startedAt: "2025-11-18T08:22:50.988578Z"
                writerId: wcbwlxdcd8v0mwr49iqro9glikqfdqim
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 5
                - 11
                - 49
                - 53
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 53
            "3":
                - 2
                - 16
                - 61
            "4": 3.12.3
            "5": 0.23.0
            "6": 4.57.1
            "12": 0.23.0
            "13": linux-x86_64
BATCH_SIZE:
    value: 16
EPOCHS:
    value: 8
NUM_WARMUP_STEPS:
    value: 50
PEAK_LR:
    value: 1e-06
SAVE_PATH:
    value: models/router_qwen2.5
WEIGHT_DECAY:
    value: 0.04
base:
    value: Qwen/Qwen2.5-1.5B-Instruct
device:
    value: cuda
model_keys:
    value:
        gemini-2.5-flash-lite_response:
            - 0.1
            - 0.4
        gpt-5-nano-2025-08-07_response:
            - 0.05
            - 0.4
        grok-4-fast-reasoning_response:
            - 0.2
            - 0.5
        meta-llama_Llama-3.2-11B-Vision-Instruct_response:
            - 0.049
            - 0.049
        moonshotai_Kimi-K2-Instruct-0905_response:
            - 0.5
            - 2
        nvidia_NVIDIA-Nemotron-Nano-9B-v2_response:
            - 0.04
            - 0.16
        openai_gpt-oss-20b_response:
            - 0.03
            - 0.14
        openai_gpt-oss-120b_response:
            - 0.05
            - 0.24
